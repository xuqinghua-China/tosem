
# Digital Twin-based Anomaly Detection with Curriculum Learning in Cyber-physical Systems

# Abstract
Anomaly detection is critical to ensure the security of cyber-physical systems (CPS). However, due to theincreasing complexity and more sophisticated attacks, tackling the anomaly detection task in CPS is becomingmore and more challenging. In our previous work, we proposed a digital twin-based anomaly detection methodcalled ATTAIN, which takes advantage of both historical and real-time data of CPS. However, these samples canvary significantly in terms of difficulty, therefore, similar to human learning processes, deep learning models,i.e., ATTAIN, can benefit from an easy-to-difficult curriculum. To this end, we present a novel approach, calleddigitaL twin-based Anomaly deTecTion wIth Curriculum lEarning (LATTICE), by introducing curriculumlearning to optimize the learning paradigm of ATTAIN. LATTICE uses a difficulty scorer to assign scores foreach sample, which is then fed into a training scheduler. The training scheduler samples batches of trainingdata based on these scores to perform learning from easy to difficult data. To evaluate our approach, we usedfive publicly available datasets collected from five CPS testbeds. We compare LATTICE with ATTAIN and twoother state-of-the-art anomaly detectors. Evaluation results show that LATTICE improves the performance of the baselines by 0.906%-2.367% in terms of F1 score.
# Overview
![overview](https://user-images.githubusercontent.com/62027704/141008868-0220f42b-1dcb-4791-9f0a-57fa7b641118.png)
LATTICE follows the general CL framework proposed in [28], as we discussed in Section 2, withthe main idea of training models from easier data to harder data. Therefore, a general CL designconsists ofDifficulty MeasurerandTraining Scheduler, which, respectively, decide the relative"easiness" of each sample and the sequence of data subsets throughout the training process basedon the judgment ofDifficulty Measurer. As shown in Figure 3, all the training examples are sortedby theDifficulty Measurerfrom the easiest to the hardest and passed to theTraining Scheduler. Then, at each training epochğ‘¡, theTraining Schedulersamples a batch of training data from therelatively easier examples, and sends it to theATTAINfor training. With progressing trainingepochs, theTraining Schedulerdecides when to sample from harder data. As shown in the runningexample (Table 1), the Difficulty column presents the difficulty scores given by theDifficultyMeasurer, indicating the relative "easiness" of each sample. For instance, the sample data at 10:00:00is assigned a difficulty score of 0.9, i.e,ğ‘ ğ‘ğ‘œğ‘Ÿğ‘’(ğ‘¢10:00:00)=0.9, while the difficulty score of the sampleat 10:29:12 is 0.5, i.e,ğ‘ ğ‘ğ‘œğ‘Ÿğ‘’(ğ‘¢10:29:12)=0.5. This tells that sampleğ‘¢10:00:00is relatively harder for themodel to learn. With these difficulty scores, the training scheduler decides which samples shouldbe included in each batch. The general principle is that easy samples should be included first. Aftercalculation, the training scheduler assigns new batch numbers forğ‘¢10:00:00(batch number=23) andğ‘¢10:19:12(batch number=2). In the following section, we will present more details about theDifficultyMeasurer,Training Schedulerand the extension to ATTAIN in Section 5.1, Section 5.2, and Section5.3, respectively
# Dataset
![dataset](https://user-images.githubusercontent.com/62027704/141009105-e7cbee65-c6f6-48e6-9ea6-6ff6c2596132.png)
Due to copyright issues, we can not include public dataset in this repository. The references of the datasets are provided as follows.
1. **SWaT.** Mathur AP, Tippenhauer NO. SWaT: a water treatment testbed for research and training on ICS security. In: 2016 International Workshop on Cyber-physical Systems for Smart Water Networks (CySWater). IEEE; 2016. p. 31â€“6. 
2. **WADI.** Ahmed CM, Palleti VR, Mathur AP. WADI: a water distribution testbed for research in the design of secure cyber physical systems. In: Proceedings of the 3rd International Workshop on Cyber-Physical Systems for Smart Water Networks. 2017. p. 25â€“8. 
3. **BATADAL.** Taormina R, Galelli S, Tippenhauer NO, Salomons E, Ostfeld A, Eliades DG, et al. The Battle Of The Attack Detection Algorithms: Disclosing Cyber Attacks On Water Distribution Networks. J Water Resour Plan Manag. 2018 Aug;144(8):4018048. 
4. **PHM2015 Challenge.** Xiao W. A probabilistic machine learning approach to detect industrial plant faults: PHM15 data challenge. Proc Annu Conf Progn Heal Manag Soc PHM. 2015;(c):718â€“26. 
5. **Gas Pipeline Dataset.** Morris TH, Thornton Z, Turnipseed I. Industrial Control System Simulation and Data Logging for Intrusion Detection System Research. Seventh Annu Southeast Cyber Secur Summit [Internet]. 2015;6. Available from: http://files/2536/Morris et al. - Industrial Control System Simulation and Data Logg.pdf%0Ahttp://www.ece.uah.edu/~thm0009/icsdatasets/cyberhuntsvillepaper_v4.pdf
# Train
